{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Evaluation of the MLM models</h1></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_excel(\"../../Datasets/bert-base-uncased.xlsx\")\n",
    "df_roberta = pd.read_excel(\"../../Datasets/roberta-base_pred.xlsx\")\n",
    "df_distilroberta = pd.read_excel(\"../../Datasets/distilroberta-base_pred.xlsx\")\n",
    "df_albert = pd.read_excel(\"../../Datasets/albert-base_pred.xlsx\")\n",
    "df_ditilbert = pd.read_excel(\"../../Datasets/distilbert-base-uncased_pred_ngram.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-log-likelihood (PLL) and Perplexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLL\n",
    "\n",
    "Pseudo-log-likelihood (PLL) is a scoring method used in language modeling, taken from the pdf here : https://aclanthology.org/2020.acl-main.240.pdf. \n",
    "\n",
    "It calculates the probability of a word given its previous words in a sentence, by treating the remaining words as a set of distractors.\n",
    "\n",
    "\n",
    "The PLL score is calculated as follows:\n",
    "1.\n",
    "For each word w in the sentence, PLL computes its log probability given the preceding words. This is done by taking the sum of the log probabilities of the word w given each of the preceding words in the sentence.\n",
    "2.\n",
    "The PLL score is then computed as the sum of these log probabilities, divided by the number of words in the sentence minus 1. The minus 1 is used to exclude the last word in the sentence, which has no succeeding words.\n",
    "\n",
    "\n",
    "//\n",
    "Lower PLL values indicate that the model assigns higher probabilities to the true tokens in the input text, which means that the model is better at predicting the masked tokens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perplexity "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is a measure of how well a probability distribution or model predicts a sample. \n",
    "It is calculated as the exponential of the cross-entropy loss between the predicted token probabilities and the true tokens. \n",
    "\n",
    "\n",
    "//\n",
    "Lower perplexity values indicate that the model assigns higher probabilities to the true tokens in the input text, which means that the model is better at predicting the next token in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "def compute_pll(sentences, model_name= 'bert-base-uncased'):\n",
    "    # Gett model n tokenizer \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "    # Init  PLL values\n",
    "    pll_values = []\n",
    "\n",
    "    # Cal PLL for chaque sentence bu\n",
    "    for sentence in sentences:\n",
    "        # Tokenizeing\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        input_ids = input_ids[0]\n",
    "\n",
    "        # Init pll value \n",
    "        pll = 0\n",
    "\n",
    "        # Cal cond log probability for chaue jeton \n",
    "        for i in range(1, len(input_ids)-1):\n",
    "            # Create input with masked token\n",
    "            masked_input_ids = input_ids.numpy().copy()\n",
    "            masked_input_ids[i] = tokenizer.mask_token_id\n",
    "\n",
    "            # Cal log probabilities for masked eton\n",
    "            outputs = model(tf.convert_to_tensor(masked_input_ids[None, :]))\n",
    "            log_probs = tf.nn.log_softmax(outputs[0][0, i], axis=0)\n",
    "\n",
    "            # Update pll\n",
    "            pll += log_probs[input_ids[i]].numpy()\n",
    "\n",
    "        # Append PLL value to list\n",
    "        pll_values.append(pll)\n",
    "\n",
    "    return pll_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This is love\n",
      "PLL: -13.75\n",
      "\n",
      "Sentence: This is awsome\n",
      "PLL: -38.41\n",
      "\n",
      "Sentence: I love you\n",
      "PLL: -7.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = ['This is love', 'This is awsome', 'I love you']\n",
    "model_name = 'bert-base-uncased'\n",
    "pll_values = compute_pll(sentences, model_name)\n",
    "\n",
    "for sentence, pll in zip(sentences, pll_values):\n",
    "    print(f'Sentence: {sentence}')\n",
    "    print(f'PLL: {pll:.2f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, TFAutoModelForCausalLM\n",
    "\n",
    "def calculate_perplexities(sentences, model_name='bert-base-uncased'):\n",
    "    if model_name in ['distilbert-base-uncased', 'albert-base-v2']:\n",
    "        model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    else:\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    perplexities = []\n",
    "    for sentence in sentences:\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = tf.math.exp(loss).numpy()[0]\n",
    "        perplexities.append(perplexity)\n",
    "    return perplexities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.645836, 274.9464]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "sentences = ['Life is life.', 'I love natural language processing.']\n",
    "\n",
    "perplexities = calculate_perplexities(sentences, model_name)\n",
    "\n",
    "print(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def shortest_path_distance(s1, s2):\n",
    "    synset1 = wn.synset(s1)\n",
    "    synset2 = wn.synset(s2)\n",
    "    distance = synset1.shortest_path_distance(synset2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_similarity(s1, s2):\n",
    "    distance = shortest_path_distance(s1, s2)\n",
    "    if distance is None:\n",
    "        return 0\n",
    "    similarity = 1 / (distance + 1)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(model_name, sentences):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    accuracies = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenizeing\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        # Masking\n",
    "        mask_index = 2\n",
    "        original_word = sentence.split()[mask_index]\n",
    "        input_ids_np = input_ids.numpy()\n",
    "        input_ids_np[0][mask_index] = tokenizer.mask_token_id\n",
    "        input_ids = tf.convert_to_tensor(input_ids_np)\n",
    "        # predictions\n",
    "        outputs = model(input_ids)\n",
    "        predictions = tf.argsort(outputs[0][0][mask_index], direction='DESCENDING')\n",
    "        similarities = []\n",
    "        for prediction in predictions:\n",
    "            predicted_word = tokenizer.decode([prediction])\n",
    "            synsets1 = wn.synsets(original_word)\n",
    "            synsets2 = wn.synsets(predicted_word)\n",
    "            if synsets1 and synsets2:\n",
    "                max_similarity = max(path_similarity(synset1.name(), synset2.name()) for synset1 in synsets1 for synset2 in synsets2)\n",
    "                similarities.append(max_similarity)\n",
    "            else:\n",
    "                similarities.append(0)\n",
    "        accuracy = max(similarities)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n",
      "[1.0, 0.5]\n",
      "[1.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "sentences = ['I love me', 'I love oreo games']\n",
    "accuracies = calculate_accuracies(model_name, sentences)\n",
    "print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "def calculate_execution_time(sentences, n_runs=10, model_name='bert-base-uncased'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    execution_times = []\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.time()\n",
    "        for sentence in sentences:\n",
    "            input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "            model(input_ids)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    min_time = min(execution_times)\n",
    "    max_time = max(execution_times)\n",
    "    normalized_times = [(x - min_time) / (max_time - min_time) for x in execution_times]\n",
    "    return normalized_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2349083961266909, 0.27739495655811375, 0.4450122383453079, 0.5209804243003228, 0.0, 0.2727426894965037, 0.5893455735629131, 1.0, 0.4067709422677965, 0.12493287281730665]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "sentences = ['The cat sat on the mat', 'The quick brown fox jumps over the lazy dog']\n",
    "normalized_times = calculate_execution_time(sentences, 10,model_name)\n",
    "print(normalized_times)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('dataset.xlsx')\n",
    "df = df.iloc[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"bert-base-uncased\", \"roberta-base\", \"albert-base-v2\", \"distilroberta-base\", \"distilbert-base-uncased\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "If you want to use `TFBertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "All model checkpoint layers were used when initializing TFBertLMHeadModel.\n",
      "\n",
      "All the layers of TFBertLMHeadModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertLMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1.0]\n",
      "[0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "If you want to use `TFRobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "All model checkpoint layers were used when initializing TFRobertaForCausalLM.\n",
      "\n",
      "All the layers of TFRobertaForCausalLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForCausalLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1.0]\n",
      "[0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFAlbertForMaskedLM.\n",
      "\n",
      "All the layers of TFAlbertForMaskedLM were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFAlbertForMaskedLM.\n",
      "\n",
      "All the layers of TFAlbertForMaskedLM were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFAlbertForMaskedLM.\n",
      "\n",
      "All the layers of TFAlbertForMaskedLM were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1.0]\n",
      "[0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFAlbertForMaskedLM.\n",
      "\n",
      "All the layers of TFAlbertForMaskedLM were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "If you want to use `TFRobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "All model checkpoint layers were used when initializing TFRobertaForCausalLM.\n",
      "\n",
      "All the layers of TFRobertaForCausalLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForCausalLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1.0]\n",
      "[0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1.0]\n",
      "[0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def calculate_metrics(df, models):\n",
    "    metrics = {}\n",
    "    for model in models:\n",
    "        pll_values = compute_pll(df, model)\n",
    "        perplexities = calculate_perplexities(df, model)\n",
    "        accuracies = calculate_accuracies(model, df)\n",
    "        execution_times = calculate_execution_time(df, model_name=model)\n",
    "        metrics[model] = {\n",
    "            'average_pll': mean(pll_values),\n",
    "            'average_perplexity': mean(perplexities),\n",
    "            'average_accuracy': mean(accuracies),\n",
    "            'average_execution_time': mean(execution_times)\n",
    "        }\n",
    "    return metrics\n",
    "metrics = calculate_metrics(df[:10], models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': {'average_pll': -15.020583020272898,\n",
       "  'average_perplexity': 9165004.0,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.19647058377745485},\n",
       " 'roberta-base': {'average_pll': -12.277250587474555,\n",
       "  'average_perplexity': 6894805500.0,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.3652953919089043},\n",
       " 'albert-base-v2': {'average_pll': -28.38191144168377,\n",
       "  'average_perplexity': 59.294666,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.46579976733156875},\n",
       " 'distilroberta-base': {'average_pll': -19.69064844921231,\n",
       "  'average_perplexity': 7237032400.0,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.3168013535760015},\n",
       " 'distilbert-base-uncased': {'average_pll': -18.143623085319994,\n",
       "  'average_perplexity': 42.29817,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.5216079117051494}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    n_metrics = len(next(iter(metrics.values())))\n",
    "    n_models = len(metrics)\n",
    "    x = np.arange(n_models) * 2\n",
    "    width = 0.8 / n_metrics\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for i, (metric_name, metric_values) in enumerate(zip(next(iter(metrics.values())).keys(), zip(*[model_metrics.values() for model_metrics in metrics.values()]))):\n",
    "        bar_positions = x + i * width - 0.4\n",
    "        ax.bar(bar_positions, metric_values, width, label=metric_name)\n",
    "        for j, value in enumerate(metric_values):\n",
    "            ax.text(bar_positions[j], value, f'{value:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics.keys())\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('metrique MLM.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    'bert-base-uncased': 'BERT',\n",
    "    'roberta-base': 'RoBERTa',\n",
    "    'albert-base-v2': 'AlBERT',\n",
    "    'distilroberta-base': 'DistilRoBERTa',\n",
    "    'distilbert-base-uncased': 'DistilBERT'\n",
    "}\n",
    "\n",
    "normalized_metrics = {}\n",
    "for model, model_metrics in metrics.items():\n",
    "    normalized_model_metrics = {}\n",
    "    for metric_name, metric_value in model_metrics.items():\n",
    "        if metric_name == 'average_accuracy':\n",
    "            normalized_value = metric_value\n",
    "        else:\n",
    "            min_value = min(model_metrics[metric_name] for model_metrics in metrics.values())\n",
    "            max_value = max(model_metrics[metric_name] for model_metrics in metrics.values())\n",
    "            if min_value != max_value:\n",
    "                normalized_value = (metric_value - min_value) / (max_value - min_value)\n",
    "            else:\n",
    "                normalized_value = 0\n",
    "        normalized_model_metrics[metric_name] = normalized_value\n",
    "    normalized_metrics[model_names[model]] = normalized_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERT': {'average_pll': 0.8296559947686617,\n",
       "  'average_perplexity': 0.0012663978,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.0},\n",
       " 'RoBERTa': {'average_pll': 1.0,\n",
       "  'average_perplexity': 0.9527117,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.519241543896164},\n",
       " 'AlBERT': {'average_pll': 0.0,\n",
       "  'average_perplexity': 2.3485451e-09,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.8283551607891927},\n",
       " 'DistilRoBERTa': {'average_pll': 0.5396737671877055,\n",
       "  'average_perplexity': 1.0,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 0.37009214095930043},\n",
       " 'DistilBERT': {'average_pll': 0.6357344900987364,\n",
       "  'average_perplexity': 0.0,\n",
       "  'average_accuracy': 0.9,\n",
       "  'average_execution_time': 1.0}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(normalized_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = [0.44, 0.5, 0.09, 0.39, 0.39]\n",
    "perplexity = [0.21, 0.19, 0.66, 0.3, 0.32]\n",
    "execution_time = [0.56, 0.6, 0.48, 0.38, 0.35]\n",
    "\n",
    "bins = [\"BERT\", \"RoBERTa\", \"ALBERT\", \"DistilRoBERTa\", \"DistilBERT\"]\n",
    "\n",
    "# Visualize the accuracy, perplexity and execution time of each model in a bar chart all in the same plot\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax[0].bar(bins, accuracy)\n",
    "ax[0].set_title(\"Accuracy\")\n",
    "ax[1].bar(bins, perplexity)\n",
    "ax[1].set_title(\"Perplexity\")\n",
    "ax[2].bar(bins, execution_time)\n",
    "ax[2].set_title(\"Execution time (s)\")\n",
    "\n",
    "# add title\n",
    "fig.suptitle(\"Performance of the models on a test dataset\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def remove_all(liste, value):\n",
    "    while value in liste:\n",
    "        liste.remove(value)\n",
    "    return liste\n",
    "\n",
    "def similarity(word, list_of_words):\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Get the synsets of the word\n",
    "    synsets_word = wn.synsets(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # Calculate the similarity between the word and each word in the list\n",
    "    similarities = []\n",
    "    for w in list_of_words:\n",
    "        synsets_w = wn.synsets(lemmatizer.lemmatize(w))\n",
    "        max_sim = 0\n",
    "        for synset_word in synsets_word:\n",
    "            for synset_w in synsets_w:\n",
    "                sim = synset_word.path_similarity(synset_w)\n",
    "                if sim is not None and sim > max_sim:\n",
    "                    max_sim = sim\n",
    "        similarities.append(max_sim)\n",
    "\n",
    "    if word in list_of_words:\n",
    "        similarities.append(1)\n",
    "\n",
    "    # Print the list of similarities\n",
    "    return np.max(similarities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mybase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
