{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Evaluation of the MLM models</h1></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Rania\\\\Documents\\\\GitHub\\\\Text-Combining\\\\Notebooks\\\\Metrics'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_bert = pd.read_excel(\"MLM/MLM/bert-base-uncased.xlsx\")\n",
    "df_roberta = pd.read_excel(\"MLM/MLM/roberta-base_pred.xlsx\")\n",
    "df_distilroberta = pd.read_excel(\"MLM/MLM/distilroberta-base_pred.xlsx\")\n",
    "df_albert = pd.read_excel(\"MLM/MLM/albert-base_pred.xlsx\")\n",
    "df_distilbert = pd.read_excel(\"MLM/MLM/distilbert-base-uncased_pred_ngram.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Masked sentence', 'real', 'pred'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "def compute_pll(sentences, model_name= 'bert-base-uncased'):\n",
    "    # Gett model n tokenizer \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "    # Init  PLL values\n",
    "    pll_values = []\n",
    "\n",
    "    # Cal PLL for chaque sentence bu\n",
    "    for sentence in sentences:\n",
    "        # Tokenizeing\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        input_ids = input_ids[0]\n",
    "\n",
    "        # Init pll value \n",
    "        pll = 0\n",
    "\n",
    "        # Cal cond log probability for chaue jeton \n",
    "        for i in range(1, len(input_ids)-1):\n",
    "            # Create input with masked token\n",
    "            masked_input_ids = input_ids.numpy().copy()\n",
    "            masked_input_ids[i] = tokenizer.mask_token_id\n",
    "\n",
    "            # Cal log probabilities for masked eton\n",
    "            outputs = model(tf.convert_to_tensor(masked_input_ids[None, :]))\n",
    "            log_probs = tf.nn.log_softmax(outputs[0][0, i], axis=0)\n",
    "\n",
    "            # Update pll\n",
    "            pll += log_probs[input_ids[i]].numpy()\n",
    "\n",
    "        # Append PLL value to list\n",
    "        pll_values.append(abs(pll))\n",
    "\n",
    "    return pll_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This is love\n",
      "PLL: 13.75\n",
      "\n",
      "Sentence: This is awsome\n",
      "PLL: 38.41\n",
      "\n",
      "Sentence: I love you\n",
      "PLL: 7.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = ['This is love', 'This is awsome', 'I love you']\n",
    "model_name = 'bert-base-uncased'\n",
    "pll_values = compute_pll(sentences, model_name)\n",
    "\n",
    "for sentence, pll in zip(sentences, pll_values):\n",
    "    print(f'Sentence: {sentence}')\n",
    "    print(f'PLL: {pll:.2f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, TFAutoModelForCausalLM\n",
    "\n",
    "def calculate_perplexities(sentences, model_name='bert-base-uncased'):\n",
    "    if model_name in ['distilbert-base-uncased', 'albert-base-v2']:\n",
    "        model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    else:\n",
    "        model = TFAutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    perplexities = []\n",
    "    for sentence in sentences:\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = tf.math.exp(loss).numpy()[0]\n",
    "        perplexities.append(perplexity)\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.645866, 274.9464]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "sentences = ['Life is life.', 'I love natural language processing.']\n",
    "\n",
    "perplexities = calculate_perplexities(sentences, model_name)\n",
    "\n",
    "print(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def shortest_path_distance(s1, s2):\n",
    "    synset1 = wn.synset(s1)\n",
    "    synset2 = wn.synset(s2)\n",
    "    distance = synset1.shortest_path_distance(synset2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_similarity(s1, s2):\n",
    "    distance = shortest_path_distance(s1, s2)\n",
    "    if distance is None:\n",
    "        return 0\n",
    "    similarity = 1 / (distance + 1)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(model_name, df):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = TFAutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    accuracies = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['Masked sentence']\n",
    "        # Check if sentence contains mask token\n",
    "        if tokenizer.mask_token not in sentence:\n",
    "            accuracies.append(0)\n",
    "            continue\n",
    "        # Tokenizeing\n",
    "        input_ids = tokenizer.encode(sentence, return_tensors='tf')\n",
    "        # Masking\n",
    "        mask_index = tf.where(input_ids == tokenizer.mask_token_id)[0][1]\n",
    "        original_word = row['real']\n",
    "        input_ids_np = input_ids.numpy()\n",
    "        input_ids_np[0][mask_index] = tokenizer.mask_token_id\n",
    "        input_ids = tf.convert_to_tensor(input_ids_np)\n",
    "        # predictions\n",
    "        outputs = model(input_ids)\n",
    "        predictions = tf.argsort(outputs[0][0][mask_index], direction='DESCENDING')\n",
    "        similarities = []\n",
    "        for prediction in predictions:\n",
    "            predicted_word = tokenizer.decode([prediction])\n",
    "            synsets1 = wn.synsets(original_word)\n",
    "            synsets2 = wn.synsets(predicted_word)\n",
    "            if synsets1 and synsets2:\n",
    "                max_similarity = max(path_similarity(synset1.name(), synset2.name()) for synset1 in synsets1 for synset2 in synsets2)\n",
    "                similarities.append(max_similarity)\n",
    "            else:\n",
    "                similarities.append(0)\n",
    "        accuracy = max(similarities)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert_accuracies = calculate_accuracies('bert-base-uncased', df_bert)\n",
    "roberta_accuracies = calculate_accuracies('roberta-base', df_roberta)\n",
    "distilroberta_accuracies = calculate_accuracies('distilroberta-base', df_distilroberta)\n",
    "albert_accuracies = calculate_accuracies('albert-base', df_albert)\n",
    "distilbert_accuracies = calculate_accuracies('distilbert-base-uncased', df_distilbert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_accuracies = pd.read_excel(\"MLM/MLM/bert-base_pred_with_acc.xlsx\")\n",
    "roberta_accuracies = pd.read_excel(\"MLM/MLM/roberta-base_pred_with_acc.xlsx\")\n",
    "distilroberta_accuracies = pd.read_excel(\"MLM/MLM/distilroberta-base_pred_with_acc.xlsx\")\n",
    "albert_accuracies = pd.read_excel(\"MLM/MLM/albert-base_pred_with_acc.xlsx\")\n",
    "distilbert_accuracies = pd.read_excel(\"MLM/MLM/distilbert-base_pred_with_acc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_accuracies = bert_accuracies['similarity']\n",
    "roberta_accuracies = roberta_accuracies['similarity']\n",
    "distilroberta_accuracies = distilroberta_accuracies['similarity']\n",
    "albert_accuracies = albert_accuracies['similarity']\n",
    "distilbert_accuracies = distilbert_accuracies['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "def calculate_execution_time(df, n_runs=10, model_name='bert-base-uncased'):\n",
    "    fill_mask = pipeline('fill-mask', model=model_name)\n",
    "    execution_times = []\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.time()\n",
    "        for index, row in df.iterrows():\n",
    "            sentence = row['Masked sentence']\n",
    "            fill_mask(sentence)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        execution_times.append(execution_time)\n",
    "    return execution_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert_execution_times = calculate_execution_time(df_bert, model_name='bert-base-uncased')\n",
    "roberta_execution_times = calculate_execution_time(df_roberta, model_name='roberta-base')\n",
    "distilroberta_execution_times = calculate_execution_time(df_distilroberta, model_name='distilroberta-base')\n",
    "albert_execution_times = calculate_execution_time(df_albert, model_name='albert-base-v2')\n",
    "distilbert_execution_times = calculate_execution_time(df_distilbert, model_name='distilbert-base-uncased')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('dataset.xlsx')\n",
    "df = df.iloc[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"bert-base-uncased\", \"roberta-base\", \"albert-base-v2\", \"distilroberta-base\", \"distilbert-base-uncased\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def calculate_metrics(dfs, models, average_perplexities, average_accuracies, average_execution_times):\n",
    "    metrics = {}\n",
    "    for df, model, average_perplexity, average_accuracy, average_execution_time in zip(dfs, models, average_perplexities, average_accuracies, average_execution_times):\n",
    "        pll_values = compute_pll(df['Masked sentence'], model_name=model)\n",
    "\n",
    "        min_pll, max_pll = min(pll_values), max(pll_values)\n",
    " \n",
    "        if max_pll - min_pll == 0:\n",
    "            average_pll = 1\n",
    "        else:\n",
    "            average_pll = 1 - ((mean(pll_values) - min_pll) / (max_pll - min_pll))\n",
    "\n",
    "        metrics[model] = {\n",
    "            'average_pll': average_pll,\n",
    "            'average_perplexity': average_perplexity,\n",
    "            'average_accuracy': average_accuracy,\n",
    "            'average_execution_time': average_execution_time\n",
    "        }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albert = df_albert.rename(columns={'Masked Sentence': 'Masked sentence'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Masked sentence', 'real', 'pred'], dtype='object')\n",
      "Index(['Masked sentence', 'real', 'pred'], dtype='object')\n",
      "Index(['Masked sentence', 'real', 'pred'], dtype='object')\n",
      "Index(['Masked sentence', 'real', 'pred'], dtype='object')\n",
      "Index(['Masked sentence', 'real', 'pred'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bert.columns)\n",
    "print(df_roberta.columns)\n",
    "print(df_distilroberta.columns)\n",
    "print(df_albert.columns)\n",
    "print(df_distilbert.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m average_accuracies \u001b[39m=\u001b[39m [\u001b[39m0.44\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.39\u001b[39m, \u001b[39m0.09\u001b[39m,  \u001b[39m0.39\u001b[39m]\n\u001b[0;32m      6\u001b[0m average_execution_times \u001b[39m=\u001b[39m [\u001b[39m0.56\u001b[39m, \u001b[39m0.6\u001b[39m, \u001b[39m0.38\u001b[39m, \u001b[39m0.48\u001b[39m,  \u001b[39m0.35\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m metrics \u001b[39m=\u001b[39m calculate_metrics(dfs, models, average_perplexities, average_accuracies, average_execution_times)\n",
      "Cell \u001b[1;32mIn[62], line 6\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(dfs, models, average_perplexities, average_accuracies, average_execution_times)\u001b[0m\n\u001b[0;32m      4\u001b[0m metrics \u001b[39m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m df, model, average_perplexity, average_accuracy, average_execution_time \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dfs, models, average_perplexities, average_accuracies, average_execution_times):\n\u001b[1;32m----> 6\u001b[0m     pll_values \u001b[39m=\u001b[39m compute_pll(df[\u001b[39m'\u001b[39;49m\u001b[39mMasked sentence\u001b[39;49m\u001b[39m'\u001b[39;49m], model_name\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m      8\u001b[0m     min_pll, max_pll \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(pll_values), \u001b[39mmax\u001b[39m(pll_values)\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m max_pll \u001b[39m-\u001b[39m min_pll \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m, in \u001b[0;36mcompute_pll\u001b[1;34m(sentences, model_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m masked_input_ids[i] \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mmask_token_id\n\u001b[0;32m     27\u001b[0m \u001b[39m# Cal log probabilities for masked eton\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m outputs \u001b[39m=\u001b[39m model(tf\u001b[39m.\u001b[39;49mconvert_to_tensor(masked_input_ids[\u001b[39mNone\u001b[39;49;00m, :]))\n\u001b[0;32m     29\u001b[0m log_probs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mlog_softmax(outputs[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m, i], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39m# Update pll\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\modeling_tf_utils.py:420\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    419\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1339\u001b[0m, in \u001b[0;36mTFBertForMaskedLM.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[0;32m   1310\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1311\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFMaskedLMOutput, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[0;32m   1333\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m \u001b[39m    labels (`tf.Tensor` or `np.ndarray` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[39m        Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39m        config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[39m        loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1339\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1340\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1341\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1342\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1343\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1344\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1345\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1346\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1347\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1348\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1349\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m   1350\u001b[0m     )\n\u001b[0;32m   1351\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1352\u001b[0m     prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlm(sequence_output\u001b[39m=\u001b[39msequence_output, training\u001b[39m=\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\modeling_tf_utils.py:420\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    419\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:873\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[1;32m--> 873\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    874\u001b[0m     hidden_states\u001b[39m=\u001b[39;49membedding_output,\n\u001b[0;32m    875\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    876\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    877\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    878\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    879\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    880\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    881\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    882\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    883\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    884\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    885\u001b[0m )\n\u001b[0;32m    887\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    888\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states\u001b[39m=\u001b[39msequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:564\u001b[0m, in \u001b[0;36mTFBertEncoder.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    560\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m    562\u001b[0m past_key_value \u001b[39m=\u001b[39m past_key_values[i] \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    565\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    566\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    568\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    569\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    570\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    571\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    572\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    573\u001b[0m )\n\u001b[0;32m    574\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    576\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:520\u001b[0m, in \u001b[0;36mTFBertLayer.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[0;32m    517\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    518\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 520\u001b[0m intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(hidden_states\u001b[39m=\u001b[39;49mattention_output)\n\u001b[0;32m    521\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_output(\n\u001b[0;32m    522\u001b[0m     hidden_states\u001b[39m=\u001b[39mintermediate_output, input_tensor\u001b[39m=\u001b[39mattention_output, training\u001b[39m=\u001b[39mtraining\n\u001b[0;32m    523\u001b[0m )\n\u001b[0;32m    524\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:423\u001b[0m, in \u001b[0;36mTFBertIntermediate.call\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: tf\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 423\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(inputs\u001b[39m=\u001b[39;49mhidden_states)\n\u001b[0;32m    424\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\engine\\base_layer.py:1037\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1035\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1040\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\keras\\layers\\core.py:1232\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mraw_ops\u001b[39m.\u001b[39mMatMul(a\u001b[39m=\u001b[39minputs, b\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[0;32m   1230\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1232\u001b[0m   outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtensordot(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel, [[rank \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m], [\u001b[39m0\u001b[39;49m]])\n\u001b[0;32m   1233\u001b[0m   \u001b[39m# Reshape the output back to the original ndim of the input.\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:5039\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes, name)\u001b[0m\n\u001b[0;32m   5037\u001b[0m b \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(b, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5038\u001b[0m a_axes, b_axes \u001b[39m=\u001b[39m _tensordot_axes(a, axes)\n\u001b[1;32m-> 5039\u001b[0m a_reshape, a_free_dims, a_free_dims_static \u001b[39m=\u001b[39m _tensordot_reshape(a, a_axes)\n\u001b[0;32m   5040\u001b[0m b_reshape, b_free_dims, b_free_dims_static \u001b[39m=\u001b[39m _tensordot_reshape(\n\u001b[0;32m   5041\u001b[0m     b, b_axes, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   5042\u001b[0m ab_matmul \u001b[39m=\u001b[39m matmul(a_reshape, b_reshape)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:4966\u001b[0m, in \u001b[0;36mtensordot.<locals>._tensordot_reshape\u001b[1;34m(a, axes, flipped)\u001b[0m\n\u001b[0;32m   4964\u001b[0m   a_trans \u001b[39m=\u001b[39m a\n\u001b[0;32m   4965\u001b[0m \u001b[39mif\u001b[39;00m a_trans\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mas_list() \u001b[39m!=\u001b[39m new_shape:\n\u001b[1;32m-> 4966\u001b[0m   reshaped_a \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mreshape(a_trans, new_shape)\n\u001b[0;32m   4967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4968\u001b[0m   reshaped_a \u001b[39m=\u001b[39m a_trans\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:196\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     61\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m  \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    197\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    198\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8397\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8395\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   8396\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 8397\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[0;32m   8398\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m   8399\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m   8400\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8422\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8420\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [tensor, shape]\n\u001b[0;32m   8421\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTshape\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tshape)\n\u001b[1;32m-> 8422\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat, attrs\u001b[39m=\u001b[39;49m_attrs,\n\u001b[0;32m   8423\u001b[0m                            ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   8424\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   8425\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[0;32m   8426\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReshape\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\Rania\\anaconda3\\envs\\mybase\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs = [df_bert[:500], df_roberta[:500], df_distilroberta[:500], df_albert[:500], df_distilbert[:500]]\n",
    "\n",
    "models = ['bert-base-uncased', 'roberta-base', 'distilroberta-base', 'albert-base-v2', 'distilbert-base-uncased']\n",
    "average_perplexities = [0.21, 0.19, 0.3, 0.66,  0.32]\n",
    "average_accuracies = [0.44, 0.5, 0.39, 0.09,  0.39]\n",
    "average_execution_times = [0.56, 0.6, 0.38, 0.48,  0.35]\n",
    "metrics = calculate_metrics(dfs, models, average_perplexities, average_accuracies, average_execution_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': {'average_pll': 0.6826168912717894,\n",
       "  'average_perplexity': 0.21,\n",
       "  'average_accuracy': 0.44,\n",
       "  'average_execution_time': 0.56},\n",
       " 'roberta-base': {'average_pll': 0.6944965386848241,\n",
       "  'average_perplexity': 0.19,\n",
       "  'average_accuracy': 0.5,\n",
       "  'average_execution_time': 0.6},\n",
       " 'distilroberta-base': {'average_pll': 0.7099431217984299,\n",
       "  'average_perplexity': 0.66,\n",
       "  'average_accuracy': 0.09,\n",
       "  'average_execution_time': 0.48},\n",
       " 'albert-base-v2': {'average_pll': 0.7040764222036549,\n",
       "  'average_perplexity': 0.3,\n",
       "  'average_accuracy': 0.39,\n",
       "  'average_execution_time': 0.38},\n",
       " 'distilbert-base-uncased': {'average_pll': 0.6977765947815175,\n",
       "  'average_perplexity': 0.32,\n",
       "  'average_accuracy': 0.39,\n",
       "  'average_execution_time': 0.35}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    n_metrics = len(next(iter(metrics.values())))\n",
    "    n_models = len(metrics)\n",
    "    x = np.arange(n_models) * 2\n",
    "    width = 0.8 / n_metrics\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for i, (metric_name, metric_values) in enumerate(zip(next(iter(metrics.values())).keys(), zip(*[model_metrics.values() for model_metrics in metrics.values()]))):\n",
    "        bar_positions = x + i * width - 0.4\n",
    "        ax.bar(bar_positions, metric_values, width, label=metric_name)\n",
    "        for j, value in enumerate(metric_values):\n",
    "            ax.text(bar_positions[j], value, f'{value:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics.keys())\n",
    "    ax.legend()\n",
    "    plt.savefig('metrique MLM-500-correct.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    'bert-base-uncased': 'BERT',\n",
    "    'roberta-base': 'RoBERTa',\n",
    "    'albert-base-v2': 'AlBERT',\n",
    "    'distilroberta-base': 'DistilRoBERTa',\n",
    "    'distilbert-base-uncased': 'DistilBERT'\n",
    "}\n",
    "\n",
    "normalized_metrics = {}\n",
    "for model, model_metrics in metrics.items():\n",
    "    normalized_model_metrics = {}\n",
    "    for metric_name, metric_value in model_metrics.items():\n",
    "        normalized_model_metrics[metric_name] = metric_value\n",
    "    normalized_metrics[model_names[model]] = normalized_model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BERT': {'average_pll': 0.6826168912717894,\n",
       "  'average_perplexity': 0.21,\n",
       "  'average_accuracy': 0.44,\n",
       "  'average_execution_time': 0.56},\n",
       " 'RoBERTa': {'average_pll': 0.6944965386848241,\n",
       "  'average_perplexity': 0.19,\n",
       "  'average_accuracy': 0.5,\n",
       "  'average_execution_time': 0.6},\n",
       " 'DistilRoBERTa': {'average_pll': 0.7099431217984299,\n",
       "  'average_perplexity': 0.66,\n",
       "  'average_accuracy': 0.09,\n",
       "  'average_execution_time': 0.48},\n",
       " 'AlBERT': {'average_pll': 0.7040764222036549,\n",
       "  'average_perplexity': 0.3,\n",
       "  'average_accuracy': 0.39,\n",
       "  'average_execution_time': 0.38},\n",
       " 'DistilBERT': {'average_pll': 0.6977765947815175,\n",
       "  'average_perplexity': 0.32,\n",
       "  'average_accuracy': 0.39,\n",
       "  'average_execution_time': 0.35}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_metrics(metrics): #had to make this bcz i inverted albert and distilrberta\n",
    "    new_metrics = metrics.copy()\n",
    "    albert_metrics = new_metrics['AlBERT']\n",
    "    distilroberta_metrics = new_metrics['DistilRoBERTa']\n",
    "    albert_metrics['average_perplexity'], distilroberta_metrics['average_perplexity'] = distilroberta_metrics['average_perplexity'], albert_metrics['average_perplexity']\n",
    "    albert_metrics['average_accuracy'], distilroberta_metrics['average_accuracy'] = distilroberta_metrics['average_accuracy'], albert_metrics['average_accuracy']\n",
    "    albert_metrics['average_execution_time'], distilroberta_metrics['average_execution_time'] = distilroberta_metrics['average_execution_time'], albert_metrics['average_execution_time']\n",
    "    return new_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_metrics = swap_metrics(normalized_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_perplexity(metrics):\n",
    "    new_metrics = metrics.copy()\n",
    "    for model_metrics in new_metrics.values():\n",
    "        model_metrics['average_perplexity'] = 1 - model_metrics['average_perplexity']\n",
    "    return new_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_metrics = invert_perplexity(normalized_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(normalized_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = [0.44, 0.5, 0.09, 0.39, 0.39]\n",
    "perplexity = [0.21, 0.19, 0.66, 0.3, 0.32]\n",
    "execution_time = [0.56, 0.6, 0.48, 0.38, 0.35]\n",
    "\n",
    "bins = [\"BERT\", \"RoBERTa\", \"ALBERT\", \"DistilRoBERTa\", \"DistilBERT\"]\n",
    "\n",
    "# Visualize the accuracy, perplexity and execution time of each model in a bar chart all in the same plot\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax[0].bar(bins, accuracy)\n",
    "ax[0].set_title(\"Accuracy\")\n",
    "ax[1].bar(bins, perplexity)\n",
    "ax[1].set_title(\"Perplexity\")\n",
    "ax[2].bar(bins, execution_time)\n",
    "ax[2].set_title(\"Execution time (s)\")\n",
    "\n",
    "# add title\n",
    "fig.suptitle(\"Performance of the models on a test dataset\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def remove_all(liste, value):\n",
    "    while value in liste:\n",
    "        liste.remove(value)\n",
    "    return liste\n",
    "\n",
    "def similarity(word, list_of_words):\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Get the synsets of the word\n",
    "    synsets_word = wn.synsets(lemmatizer.lemmatize(word))\n",
    "\n",
    "    # Calculate the similarity between the word and each word in the list\n",
    "    similarities = []\n",
    "    for w in list_of_words:\n",
    "        synsets_w = wn.synsets(lemmatizer.lemmatize(w))\n",
    "        max_sim = 0\n",
    "        for synset_word in synsets_word:\n",
    "            for synset_w in synsets_w:\n",
    "                sim = synset_word.path_similarity(synset_w)\n",
    "                if sim is not None and sim > max_sim:\n",
    "                    max_sim = sim\n",
    "        similarities.append(max_sim)\n",
    "\n",
    "    if word in list_of_words:\n",
    "        similarities.append(1)\n",
    "\n",
    "    # Print the list of similarities\n",
    "    return np.max(similarities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mybase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
