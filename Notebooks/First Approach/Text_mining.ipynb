{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Text Preprocessing using text mining</h1></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Tasks :</u></h3> \n",
    "<h4>- Text Cleaning</h4> \n",
    "<h4>- Extraction of common and uncommon parts</h4> \n",
    "<h4>- N gram distribution on the extracted uncommon parts</h4>  \n",
    "<h4>- Apply the mask on the uncommon parts</h4> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder, TrigramAssocMeasures, TrigramCollocationFinder\n",
    "from nltk.util import ngrams\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the sentences to preprocess\n",
    "\n",
    "sentence1 = \"I love to pay my video games in my free time, especially retro video games.\"\n",
    "sentence2 = \"I love to play oreo games in my free thyme, especially retro video games.\"\n",
    "sentence3 = \"Ay live to slay video vames in my free time, especially utro video games.\"\n",
    "sentences = np.array([[sentence1], [sentence2], [sentence3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['i love to pay my video games in my free time especially retro video games'],\n",
       "       ['i love to play oreo games in my free thyme especially retro video games'],\n",
       "       ['ay live to slay video vames in my free time especially utro video games']],\n",
       "      dtype='<U73')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "def preprocess(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence[0]\n",
    "        sentence = sentence.lower()\n",
    "        #sentence_token = nltk.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        new_sentences.append([sentence])\n",
    "    return np.array(new_sentences)\n",
    "token_sentences = preprocess(sentences)\n",
    "token_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N gram distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the smallest n gram\n",
    "def get_gram_lentgh(uncommon_str_i):\n",
    "    lens = []\n",
    "    for i in range(len(uncommon_str_i[0])):\n",
    "        temp = []\n",
    "        for j in range(len(uncommon_str_i)):\n",
    "            temp.append(len(uncommon_str_i[j][i]) if type(uncommon_str_i[j][i]) == list else 1)\n",
    "        lens.append(min(temp))\n",
    "    return lens\n",
    "\n",
    "# get the original sentence in a vector form\n",
    "def get_og_sentence_vector(uncommon_str, common_sentence):\n",
    "    og_sentence_vector = []\n",
    "    temp = common_sentence.split()\n",
    "    i = 0    \n",
    "    for t in temp:\n",
    "        if t == \"#\":\n",
    "            if type(uncommon_str[i]) == list:\n",
    "                og_sentence_vector.extend(uncommon_str[i])\n",
    "            else:\n",
    "                og_sentence_vector.append(uncommon_str[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            og_sentence_vector.append(t)\n",
    "    return og_sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_distribution(uncommon_str_i, common_sentence):\n",
    "    # Initialize the list of lists that will contain the n-grams\n",
    "    final_uncommon_str_i = init_list_of_lists(len(uncommon_str_i))\n",
    "\n",
    "    nb_unc_str = 0\n",
    "\n",
    "    lens = get_gram_lentgh(uncommon_str_i) # get the length of the smallest n grams\n",
    "\n",
    "    for uncommon_str in uncommon_str_i:\n",
    "        for i in range(len(uncommon_str)):\n",
    "            # Make a copy of the current list of the current uncommon part for string 1\n",
    "            unc_str = uncommon_str[i].copy() if type(uncommon_str[i]) == list else [uncommon_str[i]]\n",
    "            og_sentence = get_og_sentence_vector(uncommon_str, common_sentence)\n",
    "            temp_uncommon = uncommon_str[i].copy() if type(uncommon_str[i]) == list else [uncommon_str[i]]\n",
    "            while len(unc_str) > lens[i]:\n",
    "                \n",
    "                bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "                # Variable containing the common words that won't allowed in the bigrams\n",
    "                common_words_str = list(set(og_sentence) - set(unc_str))\n",
    "\n",
    "                # Generate a list of all n-grams of size n for the sentence\n",
    "                n_grams_str = list(ngrams(og_sentence, 2))\n",
    "                \n",
    "                # Use the bigram collocation finder to get the best bigrams for the sentence\n",
    "                finder_str = BigramCollocationFinder.from_words(og_sentence)\n",
    "                best_bigrams_str = finder_str.nbest(bigram_measures.pmi, len(n_grams_str))\n",
    "                \n",
    "                # Filter out bigrams that contain common words from the current list of uncommon words\n",
    "                best_uncommon_ngrams_str = [ngram for ngram in best_bigrams_str if (not any(p_ngrams in ngram for p_ngrams in common_words_str))]\n",
    "                \n",
    "                # Generate the final list of uncommon n-grams for string 1 by filtering the filtered bigrams and remaining uncommon words\n",
    "                uncommon_ngrams_str = [''] * len(unc_str)\n",
    "                count1 = len(unc_str)\n",
    "                count2 = 0\n",
    "                # We loop through the best uncommon n-grams and check if they are in the uncommon words list\n",
    "                for b in best_uncommon_ngrams_str:\n",
    "                    if b[0] in unc_str and b[1] in unc_str: # if both words are in the uncommon words list\n",
    "                        uncommon_ngrams_str[unc_str.index(b[0])] = \" \".join(list(b)) # we add the n-gram to the final list\n",
    "                        count2 += 1 # we increment the number of uncommon n-grams in the final list\n",
    "                        # we remove the words of the bi-gram from the uncommon words list\n",
    "                        unc_str[unc_str.index(b[0])] = '' \n",
    "                        unc_str[unc_str.index(b[1])] = ''\n",
    "                        count1 -= 2 # we decrement the number of uncommon words in the uncommon words list\n",
    "                    if count1 + count2 == lens[i]: # if we have the number of uncommon n-grams we want\n",
    "                        break\n",
    "                if unc_str != [\"\"] * len(unc_str): # if there are still uncommon words left\n",
    "                    for j in range(len(unc_str)):\n",
    "                        if unc_str[j] != '':\n",
    "                            uncommon_ngrams_str[j] = unc_str[j] # we add the uncommon words left to the final list\n",
    "                uncommon_ngrams_str = remove_all(uncommon_ngrams_str, '') # we remove the empty strings from the final list\n",
    "                unc_str = uncommon_ngrams_str.copy() # we update the current list of uncommon words\n",
    "                og_sentence = unc_str.copy() # we update the current list of uncommon words\n",
    "            \n",
    "            final_uncommon_str_i[nb_unc_str].append(unc_str) # we add the final list of uncommon n-grams to the final list of lists\n",
    "        nb_unc_str += 1 # we increment the number of uncommon parts\n",
    "    return final_uncommon_str_i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of common and uncommon parts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the sentences into vectors\n",
    "def split_preprocess(sentences):\n",
    "    s = []\n",
    "    for sentence in sentences:\n",
    "        s.append(sentence[0].split())\n",
    "    return s\n",
    "\n",
    "# Reduce the sequences of # into one #\n",
    "def shrink(sentence):\n",
    "    temp = sentence.split()\n",
    "    b = False\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] == \"#\" and b:\n",
    "            temp[i] = \"\"\n",
    "        elif temp[i] == \"#\" and not b:\n",
    "            b = True\n",
    "        elif temp[i] != \"#\" and b:\n",
    "            b = False\n",
    "    while \"\" in temp:       \n",
    "        temp.remove(\"\")\n",
    "    \n",
    "    return \" \".join(temp)\n",
    "\n",
    "def flatten(final_uncommon_str):\n",
    "    flatten_final_uncommon_str = []\n",
    "    for i in range(len(final_uncommon_str)):\n",
    "        flatten_final_uncommon_str.append([item for sublist in final_uncommon_str[i] for item in sublist])\n",
    "    return flatten_final_uncommon_str\n",
    "\n",
    "# Init the Dynamic matrix\n",
    "def init_matrix(temp_sentence, sentences, lenght, l):\n",
    "        # initialize the L matrix with zeros\n",
    "        L = [[0] * (lenght + 1) for _ in range(len(temp_sentence) + 1)]\n",
    "\n",
    "        # fill in the L matrix using dynamic programming\n",
    "        for i in range(len(temp_sentence) + 1):\n",
    "            for j in range(lenght + 1):\n",
    "                # if either string is empty, the longest common substring is zero\n",
    "                if i == 0 or j == 0:\n",
    "                    L[i][j] = 0\n",
    "                # if the characters match, add one to the length of the longest common substring\n",
    "                elif temp_sentence[i - 1] == sentences[l][j - 1]:\n",
    "                    L[i][j] = L[i - 1][j - 1] + 1\n",
    "                # if the characters don't match, take the maximum length from the previous row or column\n",
    "                else:\n",
    "                    L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
    "        return L\n",
    "\n",
    "# init list of lists\n",
    "def init_list_of_lists(lenght):\n",
    "    list_of_lists = []\n",
    "    for i in range(lenght):\n",
    "        list_of_lists.append([])\n",
    "    return list_of_lists\n",
    "\n",
    "# remove all the occourences of a value in a list\n",
    "def remove_all(liste, value):\n",
    "    while value in liste:\n",
    "        liste.remove(value)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_and_uncommon_extraction(sentences):\n",
    "    lens = [len(s) for s in sentences]\n",
    "\n",
    "    # initialize the uncommon substring lists\n",
    "    uncommon_str_i = init_list_of_lists(len(sentences))\n",
    "\n",
    "    temp_sentence = sentences[0]\n",
    "    for l in range(1, len(sentences)):\n",
    "        # initialize the L matrix\n",
    "        L = init_matrix(temp_sentence, sentences, lens[l], l)\n",
    "\n",
    "        # calculate the index based on the length of the longer string\n",
    "        index = max(len(temp_sentence), lens[l])\n",
    "\n",
    "        # initialize the common list with empty strings\n",
    "        common = [\"\"] * (index + 1)\n",
    "        common[index] = \"\"\n",
    "\n",
    "        # set i and j to the end of each string\n",
    "        i = len(temp_sentence)\n",
    "        j = lens[l]\n",
    "        limit = abs(i - j)\n",
    "\n",
    "        # trackers to follow the uncommon substrings position\n",
    "        tracker_str1 = -1 \n",
    "        tracker_str2 = -1\n",
    "        # lists that save a sequence of uncommon substrings\n",
    "        sub_uncommon_str = []\n",
    "        sub_uncommon = []\n",
    "        # final list that contains all the uncommon substrings\n",
    "        sub_uncommon_str_i_temp = []\n",
    "        sub_uncommon_str_temp = init_list_of_lists(len(sentences))\n",
    "\n",
    "        # loop through the L matrix to find the common and uncommon substrings\n",
    "        while i > 0 and j > 0:\n",
    "            # if the characters match, add the character to the common list and move to the previous diagonal cell\n",
    "            dist = abs(i - j)\n",
    "            if temp_sentence[i - 1] == sentences[l][j - 1] and dist <= limit:\n",
    "                common[index - 1] = temp_sentence[i - 1]\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "                index -= 1\n",
    "            # if the length of the substring from the previous column is greater, add the uncommon character to uncommon_str list and move to the previous column\n",
    "            elif L[i - 1][j] < L[i][j - 1]:\n",
    "                if tracker_str1 == -1: # if the tracker is -1, it means that the substring is the first one\n",
    "                    tracker_str1 = j - 1\n",
    "                    sub_uncommon_str.append(sentences[l][j - 1]) # add the uncommon character to the list\n",
    "                elif tracker_str1 == j: # if the tracker is equal to the current index, it means that the substring is part of the same sequence\n",
    "                    sub_uncommon_str.append(sentences[l][j - 1]) # add the uncommon character to the sequence list\n",
    "                    tracker_str1 = j - 1\n",
    "                else: # if the tracker is not equal to the current index, it means that the substring is part of a different sequence\n",
    "                    sub_uncommon_str.reverse() \n",
    "                    # add the sequence to the final list\n",
    "                    uncommon_str_i[l].append(sub_uncommon_str if len(sub_uncommon_str) > 1 else sub_uncommon_str[0])\n",
    "                    sub_uncommon_str = [] # reset the sequence list\n",
    "                    tracker_str1 = j - 1 # reset the tracker to the first uncommon string of the new sequence\n",
    "                    sub_uncommon_str.append(sentences[l][j - 1]) # add the uncommon string to the new sequence list\n",
    "\n",
    "                j -= 1 # move to the previous column\n",
    "            # if the length of the substring from the previous row is greater, add the uncommon character to uncommon_str2 list and move to the previous row\n",
    "            else:\n",
    "                # print(temp_sentence[i - 1])\n",
    "                if tracker_str2 == -1: # if the tracker is -1, it means that the substring is the first one\n",
    "                    tracker_str2 = i - 1\n",
    "                    sub_uncommon.append(temp_sentence[i - 1]) # add the uncommon character to the list\n",
    "                elif tracker_str2 == i: # if the tracker is equal to the current index, it means that the substring is part of the same sequence\n",
    "                    sub_uncommon.append(temp_sentence[i - 1]) # add the uncommon character to the sequence list\n",
    "                    tracker_str2 = i - 1\n",
    "                else: # if the tracker is not equal to the current index, it means that the substring is part of a different sequence\n",
    "                    sub_uncommon.reverse()\n",
    "                    if l == 1: # if the index point to the second string, it means we are dealing with the first string so we add the sequence to the final list \n",
    "                        uncommon_str_i[0].append(sub_uncommon if len(sub_uncommon) > 1 else sub_uncommon[0])\n",
    "                    else: # else it means that we are dealing with the common sentence \n",
    "                        # print(sub_uncommon)\n",
    "                        if '#' not in sub_uncommon: # if the sequence doesn't contain the # character, it means it is a new sequence so we add it to the final list directly\n",
    "                            sub_uncommon.reverse()\n",
    "                            # we add the uncommon substring to all the uncommon parts of all the previous strings\n",
    "                            for k in range(l):\n",
    "                                sub_uncommon_str_temp[k].append(sub_uncommon if len(sub_uncommon) > 1 else sub_uncommon[0])\n",
    "                        else: # if the sequence contains the # character, it means that it is a sequence that is part of a previous sequence so we need to update it\n",
    "                            sub_uncommon_copy = sub_uncommon.copy()\n",
    "                            # we add the uncommon substring to a temp list to not mess up the order of the final list\n",
    "                            sub_uncommon_str_i_temp.append(sub_uncommon_copy if len(sub_uncommon_copy) > 1 else sub_uncommon_copy[0])\n",
    "                            for k in range(l):\n",
    "                                sub_uncommon_copy = sub_uncommon.copy()\n",
    "                                uwu = 1\n",
    "                                while \"#\" in sub_uncommon_copy and len(sub_uncommon_str_i_temp) - uwu < len(uncommon_str_i[k]): # we loop through the uncommon substring and replace the # character with the uncommon substring\n",
    "                                    # we get the last uncommon substring of the previous string\n",
    "                                    updated_uncommon_str = uncommon_str_i[k][len(sub_uncommon_str_i_temp) - uwu]\n",
    "                                    if type(updated_uncommon_str) == list: # if the last uncommon substring is a list, it means that it is a sequence so we need to update it\n",
    "                                        # print(\"updated_uncommon_str : \"+str(updated_uncommon_str))\n",
    "                                        owo = len(updated_uncommon_str) - 1\n",
    "                                        while owo >= 0: # we loop through the sequence and replace the # character with the uncommon substring\n",
    "                                            if '#' in sub_uncommon_copy:\n",
    "                                                ind = max(loc for loc, val in enumerate(sub_uncommon_copy) if val == '#')\n",
    "                                                sub_uncommon_copy[ind] = updated_uncommon_str[owo]\n",
    "                                            owo -= 1\n",
    "                                    else:\n",
    "                                        ind = sub_uncommon_copy.index(\"#\")\n",
    "                                        sub_uncommon_copy[ind] = updated_uncommon_str\n",
    "                                    uwu -= 1\n",
    "                                    # print(\"sub_uncommon_copy : \"+str(sub_uncommon_copy))\n",
    "                                if \"#\" in sub_uncommon_copy:\n",
    "                                    sub_uncommon_copy = remove_all(sub_uncommon_copy, '#') # we remove all the # characters that are left\n",
    "                                sub_uncommon_str_temp[k].append(sub_uncommon_copy if len(sub_uncommon) > 1 else sub_uncommon_copy[0]) # we add the updated uncommon substring to the final list                   \n",
    "                    sub_uncommon = [] # reset the sequence list\n",
    "                    tracker_str2 = i - 1 # reset the tracker to the first uncommon string of the new sequence\n",
    "                    sub_uncommon.append(temp_sentence[i - 1]) # add the uncommon string to the new sequence list\n",
    "\n",
    "                common[index - 1] = \"#\" # add the # character to the common substring to indicate that an uncommon substring is there\n",
    "                index -= 1 # move to the previous row\n",
    "                i  -= 1 # move to the next string\n",
    "\n",
    "        if l == 1: # if the index point to the second string, it means we are dealing with the first string \n",
    "            if len(sub_uncommon) > 0: # if the length of the substring is greater than 0, it means that there is an uncommon substring left\n",
    "                sub_uncommon.reverse()\n",
    "                uncommon_str_i[0].append(sub_uncommon if len(sub_uncommon) > 1 else sub_uncommon[0]) # add the uncommon substring to the final list\n",
    "        else: # else it means that we are dealing with the common sentence\n",
    "            if len(sub_uncommon) > 0: # if the length of the substring is greater than 0, it means that there is an uncommon substring left\n",
    "                if '#' not in sub_uncommon: # if the sequence doesn't contain the # character, it means it is a new sequence so we add it to the final list directly\n",
    "                    sub_uncommon.reverse()\n",
    "                    for k in range(l):\n",
    "                        sub_uncommon_str_temp[k].append(sub_uncommon if len(sub_uncommon) > 1 else sub_uncommon[0])\n",
    "                else: # if the sequence contains the # character, it means that it is a sequence that is part of a previous sequence so we need to update it\n",
    "                    sub_uncommon.reverse()\n",
    "                    for k in range(l):\n",
    "                        sub_uncommon_copy = sub_uncommon.copy()\n",
    "                        if len(sub_uncommon_copy) < 2: # if the length of the uncommon substring is less than 2, it means that it is a sequence of a single string so we just replace the # character with the uncommon substring\n",
    "                            sub_uncommon_copy = uncommon_str_i[k][len(uncommon_str_i[k]) - 1][0] if type(uncommon_str_i[k][len(uncommon_str_i[k]) - 1]) == list else uncommon_str_i[k][len(uncommon_str_i[k]) - 1]\n",
    "                        else: # if the length of the uncommon substring is greater than 2, it means that it is a sequence so we need to update it\n",
    "                            uwu = 1\n",
    "                            while \"#\" in sub_uncommon_copy and len(uncommon_str_i[k]) - uwu >= 0: # we loop through the uncommon substring and replace the # character with the uncommon substring\n",
    "                                if type(uncommon_str_i[k][len(uncommon_str_i[k]) - uwu]) == list :\n",
    "                                    # we loop through the terms of the sequence that needs to be updated and replace the # character with the uncommon substring\n",
    "                                    for term in uncommon_str_i[k][len(uncommon_str_i[k]) - uwu]:\n",
    "                                        if '#' in sub_uncommon_copy:\n",
    "                                            ind = sub_uncommon_copy.index(\"#\")\n",
    "                                        sub_uncommon_copy[ind] = term\n",
    "                                else: # if the last uncommon substring is not a list, it means that it is a sequence of a single string so we just replace the # character with the uncommon substring\n",
    "                                    ind = sub_uncommon_copy.index(\"#\")\n",
    "                                    sub_uncommon_copy[ind] = uncommon_str_i[k][len(uncommon_str_i[k]) - 1]\n",
    "                                uwu += 1\n",
    "                        \n",
    "                        sub_uncommon_copy = remove_all(sub_uncommon_copy, \"#\") # we remove all the # characters that are left\n",
    "                        sub_uncommon_str_temp[k].append(sub_uncommon_copy) # we add the updated uncommon substring to the final list\n",
    "            # we add the uncommon substring to all the uncommon parts of all the previous strings\n",
    "            for k in range(l):\n",
    "                uncommon_str_i[k] = sub_uncommon_str_temp[k]\n",
    "\n",
    "        # we add the uncommon substring left to the current string\n",
    "        if len(sub_uncommon_str) > 0:\n",
    "            sub_uncommon_str.reverse()\n",
    "            uncommon_str_i[l].append(sub_uncommon_str if len(sub_uncommon_str) > 1 else sub_uncommon_str[0])\n",
    "        \n",
    "        if j != 0:\n",
    "            sub_uncommon_str = [] # reset the sequence list\n",
    "            while j > 0:\n",
    "                sub_uncommon_str.append(sentences[l][j - 1])\n",
    "                j -= 1\n",
    "            sub_uncommon_str.reverse()\n",
    "            # add the sequence to the final list\n",
    "            uncommon_str_i[l].append(sub_uncommon_str if len(sub_uncommon_str) > 1 else sub_uncommon_str[0])\n",
    "\n",
    "        temp_sentence = remove_all(common.copy(), \"\") # we update the common sentence\n",
    "        \n",
    "        # print(\"/////////////////////\")\n",
    "        # print(temp_sentence)\n",
    "        # print(uncommon_str_i[0])\n",
    "        # print(uncommon_str_i[1])\n",
    "        # print(uncommon_str_i[2])\n",
    "        # print(\"-------------------\")\n",
    "\n",
    "        # N-gram distribution on the uncommon parts\n",
    "        uncommon_str_i[0:l+1] = ngram_distribution(uncommon_str_i[0:l+1], shrink(\" \".join(temp_sentence)))\n",
    "        temp_sentence = shrink(\" \".join(temp_sentence))\n",
    "\n",
    "        # update the distribution of the uncommon parts based on the N-gram distribution\n",
    "        for i in range(len(uncommon_str_i[0]), 0, -1):\n",
    "            mask = \"$ \" * len(uncommon_str_i[0][i-1])\n",
    "            temp_sentence = temp_sentence.replace(\"#\", mask, 1)\n",
    "        temp_sentence = temp_sentence.replace(\"$\", \"#\")\n",
    "        temp_sentence = temp_sentence.split(\" \")\n",
    "        temp_sentence = remove_all(temp_sentence, \"\")\n",
    "\n",
    "    # join the common list into a sentence\n",
    "    common_sentence = \" \".join(temp_sentence)\n",
    "    # replace the # character with the [MASK] token\n",
    "    common_sentence = common_sentence.replace(\"#\", \"[MASK]\")\n",
    "\n",
    "    # reverse the order of the uncommon substring lists\n",
    "    for i in range(len(uncommon_str_i)):\n",
    "        uncommon_str_i[i].reverse()\n",
    "\n",
    "    # return the common sentence and the lists of uncommon substrings\n",
    "    return common_sentence, uncommon_str_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1 : I love to pay my video games in my free time, especially retro video games.\n",
      "sentence 2 : I love to play oreo games in my free thyme, especially retro video games.\n",
      "sentence 3 : Ay live to slay video vames in my free time, especially utro video games.\n",
      "\n",
      "Common parts of the sentences : [MASK] [MASK] to [MASK] [MASK] [MASK] in my free [MASK] especially [MASK] video games\n",
      "\n",
      "Uncommon parts of each sentences :\n",
      "\n",
      "sentence 1 : [['i', 'love'], ['pay my', 'video', 'games'], ['time'], ['retro']]\n",
      "\n",
      "sentence 2 : [['i', 'love'], ['play', 'oreo', 'games'], ['thyme'], ['retro']]\n",
      "\n",
      "sentence 3 : [['ay', 'live'], ['slay', 'video', 'vames'], ['time'], ['utro']]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print(\"sentence \" + str(i + 1) +\" : \"+ sentences[i][0])\n",
    "\n",
    "splited_sentences = split_preprocess(token_sentences)\n",
    "common_sentence, uncommon_str_i = common_and_uncommon_extraction(splited_sentences)\n",
    "print(\"\\nCommon parts of the sentences : \" + common_sentence)\n",
    "\n",
    "print(\"\\nUncommon parts of each sentences :\")\n",
    "for i in range(len(uncommon_str_i)):\n",
    "    print(\"\\nsentence \" + str(i + 1) +\" : \"+str(uncommon_str_i[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mining_algo(sentences):\n",
    "\n",
    "    sentences = preprocess(sentences)\n",
    "    \n",
    "    splited_sentences = split_preprocess(sentences)\n",
    "\n",
    "    common_sentence, uncommon_str_i = common_and_uncommon_extraction(splited_sentences)\n",
    "\n",
    "    return common_sentence, flatten(uncommon_str_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1 : I love to pay my video games in my free time, especially retro video games.\n",
      "sentence 2 : I love to play oreo games in my free thyme, especially retro video games.\n",
      "sentence 3 : Ay live to slay video vames in my free time, especially utro video games.\n",
      "\n",
      "Common parts of the sentences with the uncommon parts masked :\n",
      "[MASK] [MASK] to [MASK] [MASK] [MASK] in my free [MASK] especially [MASK] video games\n",
      "\n",
      "Uncommon parts of each sentence : \n",
      "\n",
      "sentence 1 : ['i', 'love', 'pay my', 'video', 'games', 'time', 'retro']\n",
      "\n",
      "sentence 2 : ['i', 'love', 'play', 'oreo', 'games', 'thyme', 'retro']\n",
      "\n",
      "sentence 3 : ['ay', 'live', 'slay', 'video', 'vames', 'time', 'utro']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print(\"sentence \" + str(i + 1) +\" : \"+ sentences[i][0])\n",
    "\n",
    "\n",
    "masked_sentence, final_uncommon_str = text_mining_algo(sentences)\n",
    "\n",
    "print(\"\\nCommon parts of the sentences with the uncommon parts masked :\\n\"+ masked_sentence) \n",
    "print(\"\\nUncommon parts of each sentence : \")\n",
    "for i in range(len(final_uncommon_str)):\n",
    "    print(\"\\nsentence \" + str(i + 1) +\" : \"+str(final_uncommon_str[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Academic Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target sentence</th>\n",
       "      <th>sentence 1</th>\n",
       "      <th>sentence 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A CAN WHET a GERARD hat is dancing.</td>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A young child is REDDING a horse.</td>\n",
       "      <td>A young TILED WIZ riding IO horse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>A man is feeding IO mouse to IO snake.</td>\n",
       "      <td>A CAN is feeding a mouse to a snake.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU guitar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU flute.</td>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Target sentence  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1      A young child is riding a horse.   \n",
       "2  A man is feeding a mouse to a snake.   \n",
       "3        A woman is playing the guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                               sentence 1  \\\n",
       "0     A CAN WHET a GERARD hat is dancing.   \n",
       "1       A young child is REDDING a horse.   \n",
       "2  A man is feeding IO mouse to IO snake.   \n",
       "3          A woman is playing the guitar.   \n",
       "4          A WAYMAN WIZ SWAYING TU flute.   \n",
       "\n",
       "                             sentence 2  \n",
       "0     A man with a hard hat is dancing.  \n",
       "1    A young TILED WIZ riding IO horse.  \n",
       "2  A CAN is feeding a mouse to a snake.  \n",
       "3       A WAYMAN WIZ SWAYING TU guitar.  \n",
       "4         A woman is playing the flute.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../Datasets/Testsets/evaluation_dataset.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sentences = df.to_numpy()\n",
    "count = 1\n",
    "eval_dataset = []\n",
    "for s in eval_sentences:\n",
    "    print(str(count)+\"/3006\")\n",
    "    sentences = np.array([[s[0]], [s[1]], [s[2]]])\n",
    "    sentences = np.array([[s[0]], [s[1]], [s[2]]])\n",
    "    temp = [s[0], s[1], s[2]]\n",
    "    masked_sentence, final_uncommon_str = text_mining_algo(sentences)\n",
    "\n",
    "    temp.append(masked_sentence)\n",
    "    lenght = len(final_uncommon_str[0])\n",
    "    b = True\n",
    "    for usi in final_uncommon_str:\n",
    "        if len(usi) != lenght:\n",
    "            b = False\n",
    "        temp.append(usi)\n",
    "    if b:\n",
    "        temp.append(\"Correct\")\n",
    "    else:\n",
    "        temp.append(\"Incorrect\")\n",
    "    eval_dataset.append(temp)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset1 = pd.DataFrame(eval_dataset, columns=['target sentence', 'noisy sentence1', 'noisy sentence2', 'common_sentence', 'uncommon_target_sentence', 'uncommon_sentence1', 'uncommon_sentence2', 'Is correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target sentence</th>\n",
       "      <th>noisy sentence1</th>\n",
       "      <th>noisy sentence2</th>\n",
       "      <th>common_sentence</th>\n",
       "      <th>uncommon_target_sentence</th>\n",
       "      <th>uncommon_sentence1</th>\n",
       "      <th>uncommon_sentence2</th>\n",
       "      <th>Is correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A CAN WHET a GERARD hat is dancing.</td>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>a [MASK] [MASK] a [MASK] hat is dancing</td>\n",
       "      <td>[man, with, hard]</td>\n",
       "      <td>[can, whet, gerard]</td>\n",
       "      <td>[man, with, hard]</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A young child is REDDING a horse.</td>\n",
       "      <td>A young TILED WIZ riding IO horse.</td>\n",
       "      <td>a young [MASK] [MASK] [MASK] [MASK] horse</td>\n",
       "      <td>[child, is, riding, a]</td>\n",
       "      <td>[child, is, redding, a]</td>\n",
       "      <td>[tiled, wiz, riding, io]</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>A man is feeding IO mouse to IO snake.</td>\n",
       "      <td>A CAN is feeding a mouse to a snake.</td>\n",
       "      <td>a [MASK] is feeding [MASK] mouse to [MASK] snake</td>\n",
       "      <td>[man, a, a]</td>\n",
       "      <td>[man, io, io]</td>\n",
       "      <td>[can, a, a]</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU guitar.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] guitar</td>\n",
       "      <td>[woman, is, playing, the]</td>\n",
       "      <td>[woman, is, playing, the]</td>\n",
       "      <td>[wayman, wiz, swaying, tu]</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU flute.</td>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] flute</td>\n",
       "      <td>[woman, is, playing, the]</td>\n",
       "      <td>[wayman, wiz, swaying, tu]</td>\n",
       "      <td>[woman, is, playing, the]</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        target sentence  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1      A young child is riding a horse.   \n",
       "2  A man is feeding a mouse to a snake.   \n",
       "3        A woman is playing the guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                          noisy sentence1  \\\n",
       "0     A CAN WHET a GERARD hat is dancing.   \n",
       "1       A young child is REDDING a horse.   \n",
       "2  A man is feeding IO mouse to IO snake.   \n",
       "3          A woman is playing the guitar.   \n",
       "4          A WAYMAN WIZ SWAYING TU flute.   \n",
       "\n",
       "                        noisy sentence2  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1    A young TILED WIZ riding IO horse.   \n",
       "2  A CAN is feeding a mouse to a snake.   \n",
       "3       A WAYMAN WIZ SWAYING TU guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                                    common_sentence  \\\n",
       "0           a [MASK] [MASK] a [MASK] hat is dancing   \n",
       "1         a young [MASK] [MASK] [MASK] [MASK] horse   \n",
       "2  a [MASK] is feeding [MASK] mouse to [MASK] snake   \n",
       "3              a [MASK] [MASK] [MASK] [MASK] guitar   \n",
       "4               a [MASK] [MASK] [MASK] [MASK] flute   \n",
       "\n",
       "    uncommon_target_sentence          uncommon_sentence1  \\\n",
       "0          [man, with, hard]         [can, whet, gerard]   \n",
       "1     [child, is, riding, a]     [child, is, redding, a]   \n",
       "2                [man, a, a]               [man, io, io]   \n",
       "3  [woman, is, playing, the]   [woman, is, playing, the]   \n",
       "4  [woman, is, playing, the]  [wayman, wiz, swaying, tu]   \n",
       "\n",
       "           uncommon_sentence2 Is correct  \n",
       "0           [man, with, hard]    Correct  \n",
       "1    [tiled, wiz, riding, io]    Correct  \n",
       "2                 [can, a, a]    Correct  \n",
       "3  [wayman, wiz, swaying, tu]    Correct  \n",
       "4   [woman, is, playing, the]    Correct  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"../../Datasets/Testsets/final-ngram-dataset-1248.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sentences = df2.to_numpy()\n",
    "count = 1\n",
    "eval_dataset = []\n",
    "for s in eval_sentences:\n",
    "    print(str(count)+\"/1242\")\n",
    "    sentences = np.array([[s[0]], [s[1]], [s[2]], [s[3]]])\n",
    "    sentences = np.array([[s[0]], [s[1]], [s[2]], [s[3]]])\n",
    "    temp = [s[0], s[1], s[2], s[3]]\n",
    "    masked_sentence, final_uncommon_str = text_mining_algo(sentences)\n",
    "\n",
    "    temp.append(masked_sentence)\n",
    "    lenght = len(final_uncommon_str[0])\n",
    "    b = True\n",
    "    for usi in final_uncommon_str:\n",
    "        if len(usi) != lenght:\n",
    "            b = False\n",
    "        temp.append(usi)\n",
    "    if b:\n",
    "        temp.append(\"Correct\")\n",
    "    else:\n",
    "        temp.append(\"Incorrect\")\n",
    "    eval_dataset.append(temp)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target sentence</th>\n",
       "      <th>noisy sentence1</th>\n",
       "      <th>noisy sentence2</th>\n",
       "      <th>noisy sentence3</th>\n",
       "      <th>common_sentence</th>\n",
       "      <th>uncommon_target_sentence</th>\n",
       "      <th>uncommon_sentence1</th>\n",
       "      <th>uncommon_sentence2</th>\n",
       "      <th>uncommon_sentence3</th>\n",
       "      <th>Is correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A CAN WHET a GERARD hat is dancing.</td>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A CAN WHET IO GER ARD AT FRIZZ DUN cing.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [M...</td>\n",
       "      <td>['man', 'with', 'a', 'hard', 'hat', 'is', 'dan...</td>\n",
       "      <td>['can', 'whet', 'a', 'gerard', 'hat', 'is', 'd...</td>\n",
       "      <td>['man', 'with', 'a', 'hard', 'hat', 'is', 'dan...</td>\n",
       "      <td>['can whet', 'io', 'ger', 'ard at', 'frizz', '...</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A young child is REDDING a horse.</td>\n",
       "      <td>A young TILED WIZ riding IO horse.</td>\n",
       "      <td>A YOUNG CHILLED HIS RED DING AI horse.</td>\n",
       "      <td>a young [MASK] [MASK] [MASK] [MASK] horse</td>\n",
       "      <td>['child', 'is', 'riding', 'a']</td>\n",
       "      <td>['child', 'is', 'redding', 'a']</td>\n",
       "      <td>['tiled', 'wiz', 'riding', 'io']</td>\n",
       "      <td>['chilled his', 'red', 'ding', 'ai']</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>A man is feeding IO mouse to IO snake.</td>\n",
       "      <td>A CAN is feeding a mouse to a snake.</td>\n",
       "      <td>A CAN BIZ SUPERSEDE MING AWE HOUSE ADO AWE snake.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [M...</td>\n",
       "      <td>['man', 'is', 'feeding', 'a', 'mouse', 'to', 'a']</td>\n",
       "      <td>['man', 'is', 'feeding', 'io', 'mouse', 'to', ...</td>\n",
       "      <td>['can', 'is', 'feeding', 'a', 'mouse', 'to', 'a']</td>\n",
       "      <td>['can', 'biz supersede', 'ming', 'awe', 'house...</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU guitar.</td>\n",
       "      <td>A WAY MAN WIZ SWAY ING TU GOY tar.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] [MASK]</td>\n",
       "      <td>['woman', 'is', 'playing', 'the', 'guitar']</td>\n",
       "      <td>['woman', 'is', 'playing', 'the', 'guitar']</td>\n",
       "      <td>['wayman', 'wiz', 'swaying', 'tu', 'guitar']</td>\n",
       "      <td>['way', 'man wiz', 'sway', 'ing tu', 'goy tar']</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU flute.</td>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>A WEY MUN ICH WAY JING TOW flute.</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] flute</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>['wayman', 'wiz', 'swaying', 'tu']</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>['wey', 'mun', 'ich way', 'jing tow']</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        target sentence  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1      A young child is riding a horse.   \n",
       "2  A man is feeding a mouse to a snake.   \n",
       "3        A woman is playing the guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                          noisy sentence1  \\\n",
       "0     A CAN WHET a GERARD hat is dancing.   \n",
       "1       A young child is REDDING a horse.   \n",
       "2  A man is feeding IO mouse to IO snake.   \n",
       "3          A woman is playing the guitar.   \n",
       "4          A WAYMAN WIZ SWAYING TU flute.   \n",
       "\n",
       "                        noisy sentence2  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1    A young TILED WIZ riding IO horse.   \n",
       "2  A CAN is feeding a mouse to a snake.   \n",
       "3       A WAYMAN WIZ SWAYING TU guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                                     noisy sentence3  \\\n",
       "0           A CAN WHET IO GER ARD AT FRIZZ DUN cing.   \n",
       "1             A YOUNG CHILLED HIS RED DING AI horse.   \n",
       "2  A CAN BIZ SUPERSEDE MING AWE HOUSE ADO AWE snake.   \n",
       "3                 A WAY MAN WIZ SWAY ING TU GOY tar.   \n",
       "4                  A WEY MUN ICH WAY JING TOW flute.   \n",
       "\n",
       "                                     common_sentence  \\\n",
       "0  a [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [M...   \n",
       "1          a young [MASK] [MASK] [MASK] [MASK] horse   \n",
       "2  a [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [M...   \n",
       "3               a [MASK] [MASK] [MASK] [MASK] [MASK]   \n",
       "4                a [MASK] [MASK] [MASK] [MASK] flute   \n",
       "\n",
       "                            uncommon_target_sentence  \\\n",
       "0  ['man', 'with', 'a', 'hard', 'hat', 'is', 'dan...   \n",
       "1                     ['child', 'is', 'riding', 'a']   \n",
       "2  ['man', 'is', 'feeding', 'a', 'mouse', 'to', 'a']   \n",
       "3        ['woman', 'is', 'playing', 'the', 'guitar']   \n",
       "4                  ['woman', 'is', 'playing', 'the']   \n",
       "\n",
       "                                  uncommon_sentence1  \\\n",
       "0  ['can', 'whet', 'a', 'gerard', 'hat', 'is', 'd...   \n",
       "1                    ['child', 'is', 'redding', 'a']   \n",
       "2  ['man', 'is', 'feeding', 'io', 'mouse', 'to', ...   \n",
       "3        ['woman', 'is', 'playing', 'the', 'guitar']   \n",
       "4                 ['wayman', 'wiz', 'swaying', 'tu']   \n",
       "\n",
       "                                  uncommon_sentence2  \\\n",
       "0  ['man', 'with', 'a', 'hard', 'hat', 'is', 'dan...   \n",
       "1                   ['tiled', 'wiz', 'riding', 'io']   \n",
       "2  ['can', 'is', 'feeding', 'a', 'mouse', 'to', 'a']   \n",
       "3       ['wayman', 'wiz', 'swaying', 'tu', 'guitar']   \n",
       "4                  ['woman', 'is', 'playing', 'the']   \n",
       "\n",
       "                                  uncommon_sentence3 Is correct  \n",
       "0  ['can whet', 'io', 'ger', 'ard at', 'frizz', '...    Correct  \n",
       "1               ['chilled his', 'red', 'ding', 'ai']    Correct  \n",
       "2  ['can', 'biz supersede', 'ming', 'awe', 'house...    Correct  \n",
       "3    ['way', 'man wiz', 'sway', 'ing tu', 'goy tar']    Correct  \n",
       "4              ['wey', 'mun', 'ich way', 'jing tow']    Correct  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset2 = pd.DataFrame(eval_dataset, columns=['target sentence', 'noisy sentence1', 'noisy sentence2', 'noisy sentence3', 'common_sentence', 'uncommon_target_sentence', 'uncommon_sentence1', 'uncommon_sentence2', 'uncommon_sentence3', 'Is correct'])\n",
    "eval_dataset2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save them as one result dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target sentence</th>\n",
       "      <th>noisy sentence1</th>\n",
       "      <th>noisy sentence2</th>\n",
       "      <th>noisy sentence3</th>\n",
       "      <th>common_sentence</th>\n",
       "      <th>uncommon_target_sentence</th>\n",
       "      <th>uncommon_sentence1</th>\n",
       "      <th>uncommon_sentence2</th>\n",
       "      <th>uncommon_sentence3</th>\n",
       "      <th>Is correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A CAN WHET a GERARD hat is dancing.</td>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>/</td>\n",
       "      <td>a [MASK] [MASK] a [MASK] hat is dancing</td>\n",
       "      <td>['man', 'with', 'hard']</td>\n",
       "      <td>['can', 'whet', 'gerard']</td>\n",
       "      <td>['man', 'with', 'hard']</td>\n",
       "      <td>/</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A young child is riding a horse.</td>\n",
       "      <td>A young child is REDDING a horse.</td>\n",
       "      <td>A young TILED WIZ riding IO horse.</td>\n",
       "      <td>/</td>\n",
       "      <td>a young [MASK] [MASK] [MASK] [MASK] horse</td>\n",
       "      <td>['child', 'is', 'riding', 'a']</td>\n",
       "      <td>['child', 'is', 'redding', 'a']</td>\n",
       "      <td>['tiled', 'wiz', 'riding', 'io']</td>\n",
       "      <td>/</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>A man is feeding IO mouse to IO snake.</td>\n",
       "      <td>A CAN is feeding a mouse to a snake.</td>\n",
       "      <td>/</td>\n",
       "      <td>a [MASK] is feeding [MASK] mouse to [MASK] snake</td>\n",
       "      <td>['man', 'a', 'a']</td>\n",
       "      <td>['man', 'io', 'io']</td>\n",
       "      <td>['can', 'a', 'a']</td>\n",
       "      <td>/</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A woman is playing the guitar.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU guitar.</td>\n",
       "      <td>/</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] guitar</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>['wayman', 'wiz', 'swaying', 'tu']</td>\n",
       "      <td>/</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>A WAYMAN WIZ SWAYING TU flute.</td>\n",
       "      <td>A woman is playing the flute.</td>\n",
       "      <td>/</td>\n",
       "      <td>a [MASK] [MASK] [MASK] [MASK] flute</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>['wayman', 'wiz', 'swaying', 'tu']</td>\n",
       "      <td>['woman', 'is', 'playing', 'the']</td>\n",
       "      <td>/</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        target sentence  \\\n",
       "0     A man with a hard hat is dancing.   \n",
       "1      A young child is riding a horse.   \n",
       "2  A man is feeding a mouse to a snake.   \n",
       "3        A woman is playing the guitar.   \n",
       "4         A woman is playing the flute.   \n",
       "\n",
       "                          noisy sentence1  \\\n",
       "0     A CAN WHET a GERARD hat is dancing.   \n",
       "1       A young child is REDDING a horse.   \n",
       "2  A man is feeding IO mouse to IO snake.   \n",
       "3          A woman is playing the guitar.   \n",
       "4          A WAYMAN WIZ SWAYING TU flute.   \n",
       "\n",
       "                        noisy sentence2 noisy sentence3  \\\n",
       "0     A man with a hard hat is dancing.               /   \n",
       "1    A young TILED WIZ riding IO horse.               /   \n",
       "2  A CAN is feeding a mouse to a snake.               /   \n",
       "3       A WAYMAN WIZ SWAYING TU guitar.               /   \n",
       "4         A woman is playing the flute.               /   \n",
       "\n",
       "                                    common_sentence  \\\n",
       "0           a [MASK] [MASK] a [MASK] hat is dancing   \n",
       "1         a young [MASK] [MASK] [MASK] [MASK] horse   \n",
       "2  a [MASK] is feeding [MASK] mouse to [MASK] snake   \n",
       "3              a [MASK] [MASK] [MASK] [MASK] guitar   \n",
       "4               a [MASK] [MASK] [MASK] [MASK] flute   \n",
       "\n",
       "            uncommon_target_sentence                  uncommon_sentence1  \\\n",
       "0            ['man', 'with', 'hard']           ['can', 'whet', 'gerard']   \n",
       "1     ['child', 'is', 'riding', 'a']     ['child', 'is', 'redding', 'a']   \n",
       "2                  ['man', 'a', 'a']                 ['man', 'io', 'io']   \n",
       "3  ['woman', 'is', 'playing', 'the']   ['woman', 'is', 'playing', 'the']   \n",
       "4  ['woman', 'is', 'playing', 'the']  ['wayman', 'wiz', 'swaying', 'tu']   \n",
       "\n",
       "                   uncommon_sentence2 uncommon_sentence3 Is correct  \n",
       "0             ['man', 'with', 'hard']                  /    Correct  \n",
       "1    ['tiled', 'wiz', 'riding', 'io']                  /    Correct  \n",
       "2                   ['can', 'a', 'a']                  /    Correct  \n",
       "3  ['wayman', 'wiz', 'swaying', 'tu']                  /    Correct  \n",
       "4   ['woman', 'is', 'playing', 'the']                  /    Correct  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_results = pd.concat([eval_dataset1, eval_dataset2], ignore_index=True)\n",
    "academic_results = academic_results[['target sentence', 'noisy sentence1', 'noisy sentence2', 'noisy sentence3', 'common_sentence', 'uncommon_target_sentence', 'uncommon_sentence1', 'uncommon_sentence2', 'uncommon_sentence3', 'Is correct']]\n",
    "academic_results[\"noisy sentence3\"] = academic_results[\"noisy sentence3\"].fillna(\"/\")\n",
    "academic_results[\"uncommon_sentence3\"] = academic_results[\"uncommon_sentence3\"].fillna(\"/\")\n",
    "academic_results.to_excel(\"../../Datasets/text_mining/text_mining_academic_results.xlsx\", index=False)\n",
    "academic_results.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EdenAI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a1b4fd6911b04e406963c399e35b474a766f02ed3e2753bf1a3fe01dba319e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
